#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒå¥½çš„å­¦ç”Ÿæ¨¡å‹
Test the trained student model
"""

import torch
import argparse
import time
from pathlib import Path
from data.cmn_hun import TranslationDataset


def load_model(model_path, device):
    """åŠ è½½æ¨¡å‹"""
    if not Path(model_path).exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    model = torch.load(model_path, map_location=device)
    model.to(device)
    model.eval()
    return model


def safe_translate(model, src_text, src_vocab, tgt_vocab, tokenizer, device, is_english=True, max_len=None):
    """å®‰å…¨çš„ç¿»è¯‘å‡½æ•°"""
    if max_len is None:
        max_len = model.positional_encoding.pe.size(1) - 2
    
    # Tokenize input
    if is_english:
        src_tokens = src_vocab(tokenizer(src_text))
    else:
        src_tokens = src_vocab(tokenizer(src_text))
    
    # Limit input length
    if len(src_tokens) > max_len - 2:
        src_tokens = src_tokens[:max_len - 2]
    
    # Create input tensor
    src_tensor = torch.tensor([0] + src_tokens + [1]).unsqueeze(0).to(device)
    
    # Start generation
    tgt = torch.tensor([[0]]).to(device)
    
    # Generate translation
    for _ in range(max_len):
        if tgt.size(1) >= max_len:
            break
        
        try:
            with torch.no_grad():
                output = model(src_tensor, tgt)
                logits = model.predictor(output[:, -1])
                next_token = torch.argmax(logits, dim=1)
                tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)
                
                if next_token.item() == 1:  # <eos>
                    break
        except Exception as e:
            print(f"ç”Ÿæˆé”™è¯¯: {e}")
            break
    
    # Convert to text
    token_list = tgt.squeeze().tolist()
    filtered_tokens = [token for token in token_list if token < len(tgt_vocab) and token not in [0, 1, 2]]
    
    if filtered_tokens:
        result = " ".join(tgt_vocab.lookup_tokens(filtered_tokens))
    else:
        result = "[ç¿»è¯‘å¤±è´¥]"
    
    return result


def test_model_quality(model, dataset, device, num_tests=10):
    """æµ‹è¯•æ¨¡å‹è´¨é‡"""
    print(f"\nğŸ” æµ‹è¯•æ¨¡å‹è´¨é‡ (éšæœº {num_tests} ä¸ªæ ·æœ¬)...")
    
    test_cases = [
        # English to Hungarian
        ("hi", True),
        ("good morning", True),
        ("thank you", True),
        ("I love you", True),
        ("How are you?", True),
    ]
    
    success_count = 0
    
    for i, (text, is_english) in enumerate(test_cases[:num_tests], 1):
        print(f"\n--- æµ‹è¯• {i}/{num_tests} ---")
        print(f"è¾“å…¥: {text} ({'è‹±è¯­' if is_english else 'åŒˆç‰™åˆ©è¯­'})")
        
        start_time = time.time()
        
        if is_english:
            result = safe_translate(
                model, text, dataset.zh_vocab, dataset.hun_vocab, 
                dataset.zh_tokenizer, device, True
            )
            print(f"åŒˆç‰™åˆ©è¯­: {result}")
        else:
            result = safe_translate(
                model, text, dataset.hun_vocab, dataset.zh_vocab,
                dataset.hun_tokenizer, device, False
            )
            print(f"è‹±è¯­: {result}")
        
        inference_time = time.time() - start_time
        print(f"æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
        
        if result != "[ç¿»è¯‘å¤±è´¥]":
            success_count += 1
            print("âœ… ç¿»è¯‘æˆåŠŸ")
        else:
            print("âŒ ç¿»è¯‘å¤±è´¥")
    
    success_rate = success_count / num_tests * 100
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"æˆåŠŸç‡: {success_rate:.1f}% ({success_count}/{num_tests})")
    
    return success_rate

import time

def interactive_test(model, dataset, device):
    """ç®€åŒ–ç‰ˆï¼šä»…æ”¯æŒè‹±æ–‡ -> åŒˆç‰™åˆ©è¯­ç¿»è¯‘"""
    print(f"\nğŸ’¬ äº¤äº’å¼ç¿»è¯‘æµ‹è¯•")
    print("ç›´æ¥è¾“å…¥è‹±æ–‡å¥å­ï¼Œè¾“å…¥ 'quit' é€€å‡º")

    while True:
        try:
            user_input = input("\nè¯·è¾“å…¥è‹±æ–‡: ").strip()

            if user_input.lower() == 'quit':
                break

            if user_input:
                start_time = time.time()
                result = safe_translate(
                    model, user_input, 
                    dataset.zh_vocab, dataset.hun_vocab,
                    dataset.zh_tokenizer, device, True
                )
                inference_time = time.time() - start_time
                print(f"è‹±æ–‡: {user_input}")
                print(f"åŒˆç‰™åˆ©è¯­: {result}")
                print(f"ç”¨æ—¶: {inference_time:.3f}ç§’")
            else:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„è‹±æ–‡å¥å­")

        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"é”™è¯¯: {e}")



def compare_with_teacher(student_model, teacher_model_path, dataset, device):
    """ä¸æ•™å¸ˆæ¨¡å‹å¯¹æ¯”"""
    print(f"\nâš–ï¸  ä¸æ•™å¸ˆæ¨¡å‹å¯¹æ¯”...")
    
    if not Path(teacher_model_path).exists():
        print(f"æ•™å¸ˆæ¨¡å‹ä¸å­˜åœ¨: {teacher_model_path}")
        return
    
    teacher_model = load_model(teacher_model_path, device)
    
    # Model statistics
    teacher_params = sum(p.numel() for p in teacher_model.parameters())
    student_params = sum(p.numel() for p in student_model.parameters())
    
    print(f"\nğŸ“Š æ¨¡å‹å¯¹æ¯”:")
    print(f"æ•™å¸ˆæ¨¡å‹å‚æ•°: {teacher_params:,}")
    print(f"å­¦ç”Ÿæ¨¡å‹å‚æ•°: {student_params:,}")
    print(f"å‹ç¼©æ¯”: {teacher_params/student_params:.2f}x")
    print(f"å‚æ•°å‡å°‘: {(1 - student_params/teacher_params)*100:.1f}%")
    
    # Translation comparison
    test_sentences = ["hi", "good morning", "thank you"]
    
    print(f"\nğŸ”„ ç¿»è¯‘è´¨é‡å¯¹æ¯”:")
    print(f"{'è¾“å…¥':<15} {'æ•™å¸ˆæ¨¡å‹':<25} {'å­¦ç”Ÿæ¨¡å‹':<25}")
    print("-" * 65)
    
    for sentence in test_sentences:
        teacher_result = safe_translate(
            teacher_model, sentence, dataset.zh_vocab, dataset.hun_vocab,
            dataset.zh_tokenizer, device, True
        )
        
        student_result = safe_translate(
            student_model, sentence, dataset.zh_vocab, dataset.hun_vocab,
            dataset.zh_tokenizer, device, True
        )
        
        print(f"{sentence:<15} {teacher_result:<25} {student_result:<25}")
    
    # Speed comparison
    print(f"\nâš¡ æ¨ç†é€Ÿåº¦å¯¹æ¯”:")
    test_text = "hello world"
    
    # Teacher speed
    start_time = time.time()
    for _ in range(10):
        safe_translate(teacher_model, test_text, dataset.zh_vocab, dataset.hun_vocab,
                      dataset.zh_tokenizer, device, True)
    teacher_time = (time.time() - start_time) / 10
    
    # Student speed
    start_time = time.time()
    for _ in range(10):
        safe_translate(student_model, test_text, dataset.zh_vocab, dataset.hun_vocab,
                      dataset.zh_tokenizer, device, True)
    student_time = (time.time() - start_time) / 10
    
    speedup = teacher_time / student_time if student_time > 0 else 0
    
    print(f"æ•™å¸ˆæ¨¡å‹å¹³å‡æ—¶é—´: {teacher_time:.4f}ç§’")
    print(f"å­¦ç”Ÿæ¨¡å‹å¹³å‡æ—¶é—´: {student_time:.4f}ç§’")
    print(f"é€Ÿåº¦æå‡: {speedup:.2f}x")


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•è®­ç»ƒå¥½çš„å­¦ç”Ÿæ¨¡å‹")
    parser.add_argument("--model_path", type=str, required=True, help="å­¦ç”Ÿæ¨¡å‹è·¯å¾„")
    parser.add_argument("--teacher_path", type=str, 
                       default="./train_process/transformer-cmn-hun/transformer_checkpoints/best.pt",
                       help="æ•™å¸ˆæ¨¡å‹è·¯å¾„")
    parser.add_argument("--mode", type=str, choices=['test', 'interactive', 'compare', 'all'],
                       default='all', help="æµ‹è¯•æ¨¡å¼")
    
    args = parser.parse_args()
    
    # Setup
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # Load dataset
    print("åŠ è½½æ•°æ®é›†...")
    dataset = TranslationDataset("data/hun-eng/hun.txt")
    
    # Load student model
    print(f"åŠ è½½å­¦ç”Ÿæ¨¡å‹: {args.model_path}")
    student_model = load_model(args.model_path, device)
    
    print(f"\nğŸ¯ å­¦ç”Ÿæ¨¡å‹æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    if args.mode in ['test', 'all']:
        success_rate = test_model_quality(student_model, dataset, device)
    
    if args.mode in ['compare', 'all']:
        compare_with_teacher(student_model, args.teacher_path, dataset, device)
    
    
    if args.mode in ['interactive', 'all']:
        interactive_test(student_model, dataset, device)
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
